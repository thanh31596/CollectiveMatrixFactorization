{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from stellargraph import StellarGraph\n",
    "# from stellargraph.mapper import At\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScalertri2VecNodeGenerator\n",
    "# from stellargraph.layer import Attri2Vec\n",
    "# from tensorflow.keras import Model, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Movie_DePaulMovie/ratings.txt',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def grid_search(model, param_grid, n_iter=300):\n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "    for params in product(*param_grid.values()):\n",
    "        params = dict(zip(param_grid.keys(), params))\n",
    "        mf = model(**params)\n",
    "        mf.factorize(iter=n_iter)\n",
    "        loss = mf.total_loss[-1]\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_params = params\n",
    "    print('Best parameters:', best_params)\n",
    "    print('Best loss:', best_loss)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34190264909304446\n"
     ]
    }
   ],
   "source": [
    "def cal(df):\n",
    "\n",
    "    \n",
    "    # calculate total number of possible user-item interactions\n",
    "    num_users = df[df.columns[0]].nunique()\n",
    "    num_items = df[df.columns[1]].nunique()\n",
    "    num_possible_interactions = num_users * num_items\n",
    "    \n",
    "    # calculate total number of actual user-item interactions\n",
    "    num_actual_interactions = df.shape[0]\n",
    "    \n",
    "    # calculate sparsity of ratings\n",
    "    sparsity = 1 - (num_actual_interactions / num_possible_interactions)\n",
    "    \n",
    "    print(sparsity)\n",
    "cal(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.356533809240531\n"
     ]
    }
   ],
   "source": [
    "def count_nan(df):\n",
    "    \"\"\"\n",
    "    Returns the percentage of NaN values in a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    total_cells = df.size\n",
    "    nan_cells = df.isna().sum().sum()\n",
    "    nan_percentage = (nan_cells / total_cells) * 100\n",
    "    print(nan_percentage)\n",
    "count_nan(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def attri2vec_embedding(graph, name):\n",
    "\n",
    "#     # Set the embedding dimension and walk number:\n",
    "#     dimension = [128]\n",
    "#     walk_number = 4\n",
    "\n",
    "#     print(f\"Training Attri2Vec for '{name}':\")\n",
    "\n",
    "#     graph_node_list = list(graph.nodes())\n",
    "\n",
    "#     # Create the biased random walker to generate random walks\n",
    "#     walker = create_biased_random_walker(graph, walk_number, walk_length)\n",
    "\n",
    "#     # Create the unsupervised sampler to sample (target, context) pairs from random walks\n",
    "#     unsupervised_samples = UnsupervisedSampler(\n",
    "#         graph, nodes=graph_node_list, walker=walker\n",
    "#     )\n",
    "\n",
    "#     # Define an Attri2Vec training generator, which generates batches of training pairs\n",
    "#     generator = Attri2VecLinkGenerator(graph, batch_size)\n",
    "\n",
    "#     # Create the Attri2Vec model\n",
    "#     attri2vec = Attri2Vec(\n",
    "#         layer_sizes=dimension, generator=generator, bias=False, normalize=None\n",
    "#     )\n",
    "\n",
    "#     # Build the model and expose input and output sockets of Attri2Vec, for node pair inputs\n",
    "#     x_inp, x_out = attri2vec.in_out_tensors()\n",
    "\n",
    "#     # Use the link_classification function to generate the output of the Attri2Vec model\n",
    "#     prediction = link_classification(\n",
    "#         output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"ip\"\n",
    "#     )(x_out)\n",
    "\n",
    "#     # Stack the Attri2Vec encoder and prediction layer into a Keras model, and specify the loss\n",
    "#     model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "#     model.compile(\n",
    "#         optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "#         loss=keras.losses.binary_crossentropy,\n",
    "#         metrics=[keras.metrics.binary_accuracy],\n",
    "#     )\n",
    "\n",
    "#     # Train the model\n",
    "#     model.fit(\n",
    "#         generator.flow(unsupervised_samples),\n",
    "#         epochs=epochs,\n",
    "#         verbose=2,\n",
    "#         use_multiprocessing=False,\n",
    "#         workers=1,\n",
    "#         shuffle=True,\n",
    "#     )\n",
    "\n",
    "#     # Build the model to predict node representations from node features with the learned Attri2Vec model parameters\n",
    "#     x_inp_src = x_inp[0]\n",
    "#     x_out_src = x_out[0]\n",
    "#     embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
    "\n",
    "#     # Get representations for all nodes in ``graph``\n",
    "#     node_gen = Attri2VecNodeGenerator(graph, batch_size).flow(graph_node_list)\n",
    "#     node_embeddings = embedding_model.predict(node_gen, workers=1, verbose=0)\n",
    "\n",
    "#     def get_embedding(u):\n",
    "#         u_index = graph_node_list.index(u)\n",
    "#         return node_embeddings[u_index]\n",
    "\n",
    "#     return get_embedding\n",
    "\n",
    "# def create_biased_random_walker(graph, walk_number, walk_length):\n",
    "#     return BiasedRandomWalk(\n",
    "#         graph,\n",
    "#         n=walk_number,\n",
    "#         length=walk_length,\n",
    "#         p=1.0,\n",
    "#         q=1.0,\n",
    "#         weighted=False,\n",
    "#         seed=None,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from stellargraph import StellarGraph\n",
    "# from stellargraph.data import BiasedRandomWalk,UnsupervisedSampler\n",
    "# from stellargraph.mapper import Attri2VecLinkGenerator, Attri2VecNodeGenerator\n",
    "# from stellargraph.layer import Attri2Vec, link_classification\n",
    "# from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "# from tensorflow.keras import Model\n",
    "# import tensorflow.keras as keras\n",
    "\n",
    "# # Assuming your dataset is a pandas DataFrame named 'data'\n",
    "# data = df\n",
    "# # Preprocess the dataset\n",
    "# data['Time'] = data['Time'].fillna('Unknown')\n",
    "# data['Location'] = data['Location'].fillna('Unknown')\n",
    "# data['Companion'] = data['Companion'].fillna('Unknown')\n",
    "\n",
    "# # Encode categorical attributes\n",
    "# time_encoder = LabelEncoder()\n",
    "# location_encoder = LabelEncoder()\n",
    "# companion_encoder = LabelEncoder()\n",
    "\n",
    "# data['Time'] = time_encoder.fit_transform(data['Time'])\n",
    "# data['Location'] = location_encoder.fit_transform(data['Location'])\n",
    "# data['Companion'] = companion_encoder.fit_transform(data['Companion'])\n",
    "\n",
    "# # Normalize numerical attributes\n",
    "# rating_scaler = MinMaxScaler()\n",
    "# data['rating'] = rating_scaler.fit_transform(data[['rating']])\n",
    "\n",
    "# # Create nodes and edges DataFrames\n",
    "# user_nodes = data[['userid', 'rating', 'Time', 'Location', 'Companion']].drop_duplicates()\n",
    "# item_nodes = pd.DataFrame(data['itemid'].unique(), columns=['itemid'])\n",
    "# edges = data[['userid', 'itemid']].values\n",
    "\n",
    "# # Concatenate user and item nodes\n",
    "# nodes = pd.concat([user_nodes.set_index('userid'), item_nodes.set_index('itemid')], axis=0).reset_index().rename(columns={'index': 'id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = StellarGraph(nodes=nodes, edges=pd.DataFrame(edges, columns=[\"source\", \"target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set parameters\n",
    "# walk_number = 4\n",
    "# walk_length = 80\n",
    "# batch_size = 50\n",
    "# epochs = 20\n",
    "\n",
    "# # Get the embeddings\n",
    "# embeddings = attri2vec_embedding(graph, \"your_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_nodes = pd.DataFrame(data['userid'].unique(), columns=['id'])\n",
    "# user_nodes['id'] = user_nodes['id'].apply(lambda x: int(f\"1{x}\"))\n",
    "\n",
    "# item_nodes = pd.DataFrame(data['itemid'].unique(), columns=['id'])\n",
    "# item_nodes['id'] = item_nodes['id'].apply(lambda x: int(f\"2{x}\"))\n",
    "\n",
    "# # Concatenate user and item nodes\n",
    "# all_nodes = pd.concat([user_nodes, item_nodes], axis=0).reset_index(drop=True)\n",
    "\n",
    "# # Update edges to match new node IDs\n",
    "# edges = data[['userid', 'itemid']].values\n",
    "# edges[:, 0] = [int(f\"1{x}\") for x in edges[:, 0]]\n",
    "# edges[:, 1] = [int(f\"2{x}\") for x in edges[:, 1]]\n",
    "\n",
    "# # Check for missing nodes\n",
    "# unique_user_ids = np.unique(edges[:, 0])\n",
    "# unique_item_ids = np.unique(edges[:, 1])\n",
    "\n",
    "# missing_users = set(unique_user_ids) - set(user_nodes['id'])\n",
    "# missing_items = set(unique_item_ids) - set(item_nodes['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = df[['userid','Location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sub=location['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_location = pd.get_dummies(location).groupby('userid').max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userid', 'itemid', 'rating', 'Time', 'Location', 'Companion'], dtype='object')\n",
      "[nan 'Cinema' 'Home']\n",
      "[nan 'Alone' 'Family' 'Partner']\n",
      "[nan 'Weekday' 'Weekend']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Movie_DePaulMovie/ratings.txt',sep=',')\n",
    "print(df.columns)\n",
    "enconder = LabelEncoder()\n",
    "df['itemid'] = enconder.fit_transform(df['itemid'])\n",
    "print(df['Location'].unique())\n",
    "print(df['Companion'].unique())\n",
    "print(df['Time'].unique())\n",
    "map_location= {'Cinema':1, 'Home':2}\n",
    "map_time= {'Weekday':1, 'Weekend':2}\n",
    "map_com= {'Alone':1, 'Family':2, 'Partner':3}\n",
    "df['Location'] = df['Location'].map(map_location)\n",
    "df['Companion'] = df['Companion'].map(map_com)\n",
    "df['Time'] = df['Time'].map(map_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_location[group_location['userid']==1117]['Location_Cinema'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in group_location.userid: \n",
    "    a = group_location[group_location['userid']==i]\n",
    "    if a['Location_Cinema'].values[0] == 0 and a['Location_Home'].values[0] == 0: \n",
    "        group_location[group_location['userid']==i]['Location_Cinema']== np.nan\n",
    "        group_location[group_location['userid']==i]['Location_Home']== np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors=int(df['userid'].value_counts().mean())\n",
    "imputer = KNNImputer(n_neighbors=neighbors)\n",
    "imputed_df = pd.DataFrame(imputer.fit_transform(df),columns=['userid', 'itemid', 'rating', 'Time', 'Location', 'Companion'])\n",
    "\n",
    "for i in imputed_df.columns: \n",
    "    imputed_df[i] = imputed_df[i].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5043 entries, 0 to 5042\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   userid     5043 non-null   int32\n",
      " 1   itemid     5043 non-null   int32\n",
      " 2   rating     5043 non-null   int32\n",
      " 3   Time       5043 non-null   int32\n",
      " 4   Location   5043 non-null   int32\n",
      " 5   Companion  5043 non-null   int32\n",
      "dtypes: int32(6)\n",
      "memory usage: 118.3 KB\n"
     ]
    }
   ],
   "source": [
    "imputed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Contextual Coeficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1:\n",
      "  Time: -0.03158532531231512\n",
      "  Location: 0.04690760992491817\n",
      "  Companion: -0.01616769671590381\n",
      "  userid: -0.03747375596930194\n",
      "Class 2:\n",
      "  Time: 0.0065272925292457285\n",
      "  Location: 0.006519460349409117\n",
      "  Companion: 0.009874143155984429\n",
      "  userid: -0.008655848509085705\n",
      "Class 3:\n",
      "  Time: 0.037668362291233756\n",
      "  Location: -0.006368485581469217\n",
      "  Companion: 0.012552323339762259\n",
      "  userid: 0.025625247216817342\n",
      "Class 4:\n",
      "  Time: 0.014235962767627222\n",
      "  Location: -0.05152486428165755\n",
      "  Companion: -0.028497176825120783\n",
      "  userid: 0.001574421196674568\n",
      "Class 5:\n",
      "  Time: -0.026845967509261506\n",
      "  Location: 0.004465631265722104\n",
      "  Companion: 0.022237915768806436\n",
      "  userid: 0.01892912594042558\n",
      "Class 1:\n",
      "  Time: -0.03494927354801354\n",
      "  Location: 0.050884080532723835\n",
      "  Companion: -0.018353010202305318\n",
      "  itemid: 0.07219850618609473\n",
      "Class 2:\n",
      "  Time: 0.005503889949451144\n",
      "  Location: 0.007458261265409745\n",
      "  Companion: 0.009169000792221332\n",
      "  itemid: 0.028467308131857005\n",
      "Class 3:\n",
      "  Time: 0.03854459590560909\n",
      "  Location: -0.008972666288127797\n",
      "  Companion: 0.012881157995160214\n",
      "  itemid: 0.018249086328948765\n",
      "Class 4:\n",
      "  Time: 0.014543313770679071\n",
      "  Location: -0.05170517835913665\n",
      "  Companion: -0.028268938928464323\n",
      "  itemid: -0.010923045636898322\n",
      "Class 5:\n",
      "  Time: -0.023642490407805524\n",
      "  Location: 0.0023351244258810236\n",
      "  Companion: 0.024575196573820405\n",
      "  itemid: -0.1079891696515419\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming your dataframe is called df\n",
    "X = imputed_df[['Time', 'Location', 'Companion','userid']]\n",
    "y = imputed_df['rating']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit the LinearSVC model\n",
    "svm = LinearSVC(random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = svm.coef_\n",
    "\n",
    "# Print the feature importances\n",
    "features = ['Time', 'Location', 'Companion','userid']\n",
    "for i in range(importances.shape[0]):\n",
    "    print(f'Class {i+1}:')\n",
    "    for j in range(importances.shape[1]):\n",
    "        print(f'  {features[j]}: {importances[i, j]}')\n",
    "\n",
    "# Calculate the mean importance for each feature across all classes\n",
    "mean_importances = np.mean(importances, axis=0)\n",
    "\n",
    "# Create a dictionary to map feature names to mean importances\n",
    "feature_importance_dict = {feature: importance for feature, importance in zip(features, mean_importances)}\n",
    "\n",
    "# Replace the values in 'Time', 'Location', and 'Companion' columns with their respective feature importances\n",
    "df_replaced = imputed_df.copy()\n",
    "for feature in features:\n",
    "    df_replaced[feature] = df_replaced[feature] * feature_importance_dict[feature]\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# X = imputed_df[['Time', 'Location', 'Companion']]\n",
    "# y = imputed_df['rating']\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Fit the AdaBoost model with a DecisionTreeClassifier as the base estimator\n",
    "# base_estimator = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "# ada = AdaBoostClassifier(base_estimator=base_estimator, random_state=42)\n",
    "# ada.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Get feature importances\n",
    "# importances = ada.feature_importances_\n",
    "\n",
    "# # Print the feature importances\n",
    "# features = ['Time', 'Location', 'Companion']\n",
    "# for i, importance in enumerate(importances):\n",
    "#     print(f'{features[i]}: {importance}')\n",
    "X_ = imputed_df[['Time', 'Location', 'Companion','itemid']]\n",
    "y_ = imputed_df['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.3, random_state=42)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit the LinearSVC model\n",
    "svm = LinearSVC(random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances_ = svm.coef_\n",
    "\n",
    "# Print the feature importances\n",
    "features_ = ['Time', 'Location', 'Companion','itemid']\n",
    "for i in range(importances_.shape[0]):\n",
    "    print(f'Class {i+1}:')\n",
    "    for j in range(importances_.shape[1]):\n",
    "        print(f'  {features_[j]}: {importances_[i, j]}')\n",
    "\n",
    "# Calculate the mean importance for each feature across all classes\n",
    "mean_importances = np.mean(importances_, axis=0)\n",
    "\n",
    "# Create a dictionary to map feature names to mean importances\n",
    "feature_importance_dict = {feature: importance for feature, importance in zip(features_, mean_importances)}\n",
    "\n",
    "# Replace the values in 'Time', 'Location', and 'Companion' columns with their respective feature importances\n",
    "df_replaced_ = imputed_df.copy()\n",
    "for feature in features_:\n",
    "    df_replaced_[feature] = df_replaced_[feature] * feature_importance_dict[feature]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "      <th>Time</th>\n",
       "      <th>Location</th>\n",
       "      <th>Companion</th>\n",
       "      <th>Time_user</th>\n",
       "      <th>Location_user</th>\n",
       "      <th>Companion_user</th>\n",
       "      <th>Time_item</th>\n",
       "      <th>Location_item</th>\n",
       "      <th>Companion_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1123</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.495331e-08</td>\n",
       "      <td>-1.296646e-07</td>\n",
       "      <td>-1.965106e-07</td>\n",
       "      <td>7.133984e-09</td>\n",
       "      <td>-7.568465e-08</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1123</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.495331e-08</td>\n",
       "      <td>-1.296646e-07</td>\n",
       "      <td>-1.965106e-07</td>\n",
       "      <td>7.133984e-09</td>\n",
       "      <td>-7.568465e-08</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1123</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.495331e-08</td>\n",
       "      <td>-1.296646e-07</td>\n",
       "      <td>-1.965106e-07</td>\n",
       "      <td>7.133984e-09</td>\n",
       "      <td>-7.568465e-08</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.495331e-08</td>\n",
       "      <td>-1.296646e-07</td>\n",
       "      <td>-1.965106e-07</td>\n",
       "      <td>7.133984e-09</td>\n",
       "      <td>-7.568465e-08</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1123</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.495331e-08</td>\n",
       "      <td>-1.296646e-07</td>\n",
       "      <td>-1.965106e-07</td>\n",
       "      <td>7.133984e-09</td>\n",
       "      <td>-7.568465e-08</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>1082</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.299066e-07</td>\n",
       "      <td>-2.593292e-07</td>\n",
       "      <td>-2.947659e-07</td>\n",
       "      <td>1.426797e-08</td>\n",
       "      <td>-1.513693e-07</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>1082</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.299066e-07</td>\n",
       "      <td>-2.593292e-07</td>\n",
       "      <td>-2.947659e-07</td>\n",
       "      <td>1.426797e-08</td>\n",
       "      <td>-1.513693e-07</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>1082</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.299066e-07</td>\n",
       "      <td>-2.593292e-07</td>\n",
       "      <td>-2.947659e-07</td>\n",
       "      <td>1.426797e-08</td>\n",
       "      <td>-1.513693e-07</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>1082</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.299066e-07</td>\n",
       "      <td>-2.593292e-07</td>\n",
       "      <td>-2.947659e-07</td>\n",
       "      <td>1.426797e-08</td>\n",
       "      <td>-1.513693e-07</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>1082</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.299066e-07</td>\n",
       "      <td>-2.593292e-07</td>\n",
       "      <td>-2.947659e-07</td>\n",
       "      <td>1.426797e-08</td>\n",
       "      <td>-1.513693e-07</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5043 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userid  itemid  rating  Time  Location  Companion     Time_user  \\\n",
       "0       1123      58       2     1         1          2  6.495331e-08   \n",
       "1       1123      33       4     1         1          2  6.495331e-08   \n",
       "2       1123       1       5     1         1          2  6.495331e-08   \n",
       "3       1123       0       3     1         1          2  6.495331e-08   \n",
       "4       1123      10       3     1         1          2  6.495331e-08   \n",
       "...      ...     ...     ...   ...       ...        ...           ...   \n",
       "5038    1082      35       1     2         2          3  1.299066e-07   \n",
       "5039    1082      62       2     2         2          3  1.299066e-07   \n",
       "5040    1082      25       1     2         2          3  1.299066e-07   \n",
       "5041    1082      50       1     2         2          3  1.299066e-07   \n",
       "5042    1082      49       1     2         2          3  1.299066e-07   \n",
       "\n",
       "      Location_user  Companion_user     Time_item  Location_item  \\\n",
       "0     -1.296646e-07   -1.965106e-07  7.133984e-09  -7.568465e-08   \n",
       "1     -1.296646e-07   -1.965106e-07  7.133984e-09  -7.568465e-08   \n",
       "2     -1.296646e-07   -1.965106e-07  7.133984e-09  -7.568465e-08   \n",
       "3     -1.296646e-07   -1.965106e-07  7.133984e-09  -7.568465e-08   \n",
       "4     -1.296646e-07   -1.965106e-07  7.133984e-09  -7.568465e-08   \n",
       "...             ...             ...           ...            ...   \n",
       "5038  -2.593292e-07   -2.947659e-07  1.426797e-08  -1.513693e-07   \n",
       "5039  -2.593292e-07   -2.947659e-07  1.426797e-08  -1.513693e-07   \n",
       "5040  -2.593292e-07   -2.947659e-07  1.426797e-08  -1.513693e-07   \n",
       "5041  -2.593292e-07   -2.947659e-07  1.426797e-08  -1.513693e-07   \n",
       "5042  -2.593292e-07   -2.947659e-07  1.426797e-08  -1.513693e-07   \n",
       "\n",
       "      Companion_item  \n",
       "0           0.000001  \n",
       "1           0.000001  \n",
       "2           0.000001  \n",
       "3           0.000001  \n",
       "4           0.000001  \n",
       "...              ...  \n",
       "5038        0.000002  \n",
       "5039        0.000002  \n",
       "5040        0.000002  \n",
       "5041        0.000002  \n",
       "5042        0.000002  \n",
       "\n",
       "[5043 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df['Time_user'] = df_replaced['Time']\n",
    "imputed_df['Location_user']= df_replaced['Location']\n",
    "imputed_df['Companion_user']= df_replaced['Companion']\n",
    "imputed_df['Time_item'] = df_replaced_['Time']\n",
    "imputed_df['Location_item']= df_replaced_['Location']\n",
    "imputed_df['Companion_item']= df_replaced_['Companion']\n",
    "imputed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.000182\n",
       "1      -0.000182\n",
       "2      -0.000182\n",
       "3      -0.000182\n",
       "4      -0.000182\n",
       "          ...   \n",
       "5038   -0.000175\n",
       "5039   -0.000175\n",
       "5040   -0.000175\n",
       "5041   -0.000175\n",
       "5042   -0.000175\n",
       "Name: userid, Length: 5043, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_replaced.head(30)\n",
    "global_mean = df_replaced[\"rating\"].mean()\n",
    "user_bias = df_replaced.groupby(\"userid\")[\"rating\"].mean() - global_mean\n",
    "item_bias = df_replaced.groupby(\"itemid\")[\"rating\"].mean() - global_mean\n",
    "df_replaced['userid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thanh\\OneDrive - Queensland University of Technology\\dataPHD\\pytorchhere.venv\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "rating_matrix = df_replaced[['userid','itemid','rating']].pivot_table(values='rating',index='userid',columns='itemid')\n",
    "model = NMF(n_components=neighbors, init='random', random_state=0) #n_component = KNN values\n",
    "U_matrix = model.fit_transform(rating_matrix.fillna(0).values)\n",
    "V_matrix = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_int(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return int(x)\n",
    "rating_matrix=rating_matrix.applymap(to_int)\n",
    "def objective_function(R, P, Q, U, V, E, D, C_u,C_i,  L_U, L_V, lambdas, b_u, b_v):\n",
    "    \"\"\"Objective function\n",
    "\n",
    "    Args:\n",
    "        R (scalar): rating value\n",
    "        P (matrix): user attribute matrix (uxp)\n",
    "        Q (matrix): item attribute matrix (vxq)\n",
    "        U (vector): user latent vector\n",
    "        V (vector): item latent vector\n",
    "        E (matrix): random matrix shape pxk\n",
    "        D (maitr): random matrix shape qxk\n",
    "        C (scalar): contextual coefficient\n",
    "        L_U (matrix): laplacian matrix for U\n",
    "        L_V (matrix): laplacian matrix for V\n",
    "        lambdas (list): a list of lambdas\n",
    "        b_u (scalar): bias of user\n",
    "        b_v (scalar): bias of item\n",
    "\n",
    "    Returns:\n",
    "        loss: loss value \n",
    "    \"\"\"\n",
    "    #First situation: both user and item attributes are not available\n",
    "    if P == None and Q ==None and E == None and D == None: \n",
    "        P =0\n",
    "        E =0\n",
    "        D = 0 \n",
    "        Q = 0\n",
    "    U=U+0.000000000005\n",
    "    V=V+0.000000000005\n",
    "    M = U.shape[0] #number of user\n",
    "    V_=0\n",
    "    U_=0\n",
    "    for ue,ve in zip(C_u,C_i):\n",
    "        U_ += ue*U\n",
    "        V_ += ve*V\n",
    "    U_mean=U_/M\n",
    "    V_mean=V_/M\n",
    "    R_pred = (U_mean + U) @ (V.T + V_mean)\n",
    "    if P !=0:\n",
    "        P_pred = U @ E.T\n",
    "        Q_pred = V @ D.T\n",
    "    else:\n",
    "        P_pred = 0\n",
    "        Q_pred = 0\n",
    "    \n",
    "    loss = np.sum((R - R_pred)**2) + np.sum((P - P_pred)**2) + np.sum((Q - Q_pred)**2)\n",
    "    loss += lambdas[0] * np.sum(U**2) + lambdas[1] * np.sum(V**2) + lambdas[2] * np.sum(D**2) + lambdas[3] * np.sum(E**2)\n",
    "    # loss += lambdas[4] * np.trace(U.T @ L_U @ U) + lambdas[5] * np.trace(V.T @ L_V @ V)\n",
    "    loss += b_u + b_v\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_matrix_similarity(matrix):\n",
    "    similarity_matrix = matrix @ matrix.T\n",
    "    np.fill_diagonal(similarity_matrix, 0)\n",
    "    return similarity_matrix\n",
    "\n",
    "def degree_matrix(adj_matrix):\n",
    "    degree_vector = np.sum(adj_matrix, axis=1)\n",
    "    return np.diag(degree_vector)\n",
    "\n",
    "def laplacian_matrix(adj_matrix):\n",
    "    deg_matrix = degree_matrix(adj_matrix)\n",
    "    return deg_matrix - adj_matrix\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "# Compute adjacency matrices based on similarity\n",
    "user_adj_matrix = adjacency_matrix_similarity(U_matrix)\n",
    "item_adj_matrix = adjacency_matrix_similarity(V_matrix)\n",
    "\n",
    "# Compute Laplacian matrices\n",
    "L_U = laplacian_matrix(user_adj_matrix)\n",
    "L_V = laplacian_matrix(item_adj_matrix)\n",
    "# Get context matrix\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Cu=imputed_df[['Time_user',\t'Location_user',\t'Companion_user']]\n",
    "Ci=imputed_df[['Time_item',\t'Location_item',\t'Companion_item']]\n",
    "C_umatrix =  scaler.fit_transform(Cu)\n",
    "C_imatrix =  scaler.fit_transform(Ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "class MultiMF: \n",
    "    def __init__(self,R_, P_, Q_, U_, V_, E_, D_, C_u_,C_i_,  L_U_, L_V_, lambdas_, b_u_, b_v_,alpha):\n",
    "        self.R_matrix = np.array(R_)\n",
    "        self.P_matrix = np.array(P_) \n",
    "        self.Q_matrix = np.array(Q_) \n",
    "        self.lambdas = lambdas_ \n",
    "        self.U_matrix = np.array(U_) \n",
    "        self.V_matrix = np.array(V_) \n",
    "        self.E_matrix = np.array(E_)\n",
    "        self.D_matrix = np.array(D_) \n",
    "        self.C_umatrix=np.array(C_u_) \n",
    "        self.C_imatrix=np.array(C_i_) \n",
    "        self.L_U=L_U_\n",
    "        self.L_V=L_V_\n",
    "        self.item_bias=np.array(b_v_)\n",
    "        self.user_bias=np.array(b_u_)\n",
    "        self.newU=[]\n",
    "        self.newV=[]\n",
    "        self.newE=[]\n",
    "        self.newD=[]\n",
    "        self.alpha=alpha\n",
    "        self.total_loss=[0]\n",
    "    def factorize(self,iter=10):\n",
    "        self.run_func()\n",
    "        for k in tqdm(range(iter)):\n",
    "            if abs(self.total_loss[-1] - self.total_loss[-2]) < 0.00000004:\n",
    "                print(\"Success\")\n",
    "                break\n",
    "            else: \n",
    "                # self.U_matrix=np.array(self.newU)\n",
    "                # self.V_matrix=np.array(self.newV).T\n",
    "                # self.D_matrix=np.array(self.newD)\n",
    "                # self.E_matrix=np.array(self.newE)\n",
    "                # self.newU=[]\n",
    "                # self.newV=[]\n",
    "                # self.newE=[]\n",
    "                # self.newD=[]\n",
    "                self.run_func()\n",
    "        return self.U_matrix, self.V_matrix\n",
    "    def run_func(self): \n",
    "        loss_col = 0 \n",
    "        lambdas=self.lambdas\n",
    "        for i in range(len(self.R_matrix)):  #70\n",
    "            loss_row = 0\n",
    "            U = self.U_matrix[i]\n",
    "            C_u = self.C_umatrix[i,:]\n",
    "            C_i = self.C_imatrix[i,:]\n",
    "            b_u=self.user_bias[i]\n",
    "            for j in range(len(self.R_matrix[i])): #97\n",
    "\n",
    "                \n",
    "\n",
    "                if not np.isnan(self.R_matrix[i,j]):\n",
    "\n",
    "                    R = self.R_matrix[i,j]\n",
    "                    V = self.V_matrix.T[j]\n",
    "                    b_v=self.item_bias[j]\n",
    "                    #First situation\n",
    "                    P=Q=L_U=L_V=E=D=0\n",
    "\n",
    "                    U, V, D, E = self.update_U_V_E_D(R=R, P=0, E=0, D=0, Q=0, U=U, V=V, C_u=C_u, C_i=C_i, lambdas=lambdas)\n",
    "                    loss,U_o,V_o,D_o,E_o = self.objective_function(R, P, Q, U, V, E, D, C_u,C_i,  L_U, L_V, lambdas, b_u, b_v)\n",
    "\n",
    "                    self.U_matrix[i] = U\n",
    "                    self.V_matrix.T[j] = V\n",
    "                    \n",
    "                    loss_row+=loss\n",
    "                    # U_ = self.update_U(R, P, Q, U, V, E, D, C_u, C_i, lambdas, alpha)\n",
    "            loss_col+=loss_row\n",
    "        self.total_loss.append(loss_col)\n",
    "    def objective_function(self,R, P, Q, U, V, E, D, C_u,C_i,  L_U, L_V, lambdas, b_u, b_v):\n",
    "        \"\"\"Objective function\n",
    "\n",
    "        Args:\n",
    "            R (scalar): rating value\n",
    "            P (matrix): user attribute matrix (uxp)\n",
    "            Q (matrix): item attribute matrix (vxq)\n",
    "            U (vector): user latent vector\n",
    "            V (vector): item latent vector\n",
    "            E (matrix): random matrix shape pxk\n",
    "            D (maitr): random matrix shape qxk\n",
    "            C (scalar): contextual coefficient\n",
    "            L_U (matrix): laplacian matrix for U\n",
    "            L_V (matrix): laplacian matrix for V\n",
    "            lambdas (list): a list of lambdas\n",
    "            b_u (scalar): bias of user\n",
    "            b_v (scalar): bias of item\n",
    "\n",
    "        Returns:\n",
    "            loss: loss value \n",
    "        \"\"\"\n",
    "        #First situation: both user and item attributes are not available\n",
    "\n",
    "        U=U+0.000000000005\n",
    "        V=V+0.000000000005\n",
    "        M = U.shape[0] #number of user\n",
    "        V_=0\n",
    "        U_=0\n",
    "        for ue,ve in zip(C_u,C_i):\n",
    "            U_ += ue*U\n",
    "            V_ += ve*V\n",
    "        U_mean=U_/M\n",
    "        V_mean=V_/M\n",
    "        R_pred = (U_mean + U) @ (V.T + V_mean)\n",
    "        if P !=0:\n",
    "            P_pred = U @ E.T\n",
    "            Q_pred = V @ D.T\n",
    "        else:\n",
    "            P_pred = 0\n",
    "            Q_pred = 0\n",
    "        \n",
    "        loss = np.sum((R - R_pred)**2) + np.sum((P - P_pred)**2) + np.sum((Q - Q_pred)**2)\n",
    "        loss += lambdas[0] * np.sum(U**2) + lambdas[1] * np.sum(V**2) + lambdas[2] * np.sum(D**2) + lambdas[3] * np.sum(E**2)\n",
    "        # loss += lambdas[4] * np.trace(U.T @ L_U @ U) + lambdas[5] * np.trace(V.T @ L_V @ V)\n",
    "        loss += b_u + b_v\n",
    "        \n",
    "        return loss,U,V,D,E\n",
    "\n",
    "    def update_U_V_E_D(self,R, P, Q, U, V, E, D, C_u,C_i,lambdas):\n",
    "        alpha=self.alpha\n",
    "        U=U+0.000000000005\n",
    "        V=V+0.000000000005\n",
    "        M = U.shape[0] #number of user\n",
    "        V_=0\n",
    "        U_=0\n",
    "        for ue,ve in zip(C_u,C_i):\n",
    "            U_ += ue*U\n",
    "            V_ += ve*V\n",
    "        U_mean=U_/M\n",
    "        V_mean=V_/M\n",
    "        if P !=0:\n",
    "            P_pred = U @ E.T\n",
    "            Q_pred = V @ D.T\n",
    "        else:\n",
    "            P_pred = 0\n",
    "            Q_pred = 0\n",
    "        R_pred = (U_mean + U) @ (V.T + V_mean)\n",
    "\n",
    "\n",
    "        dU = -2 * (R- R_pred) * (V.T + V_mean) - 2 * (P - P_pred) * E + 2 * lambdas[0] * U   \n",
    "        dV = -2 * (R - R_pred) * (U_mean + U) - 2 * (Q - Q_pred) * D + 2 * lambdas[1] * V  \n",
    "        dE = -2 * (P - P_pred) * U + 2 * lambdas[3] * E\n",
    "        dD = -2 * (Q - Q_pred) * V + 2 * lambdas[2] * D\n",
    "\n",
    "        U -= alpha * dU\n",
    "        V -= alpha * dV\n",
    "        E -= alpha * dE\n",
    "        D -= alpha * dD\n",
    "\n",
    "        return U, V, E, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:54<00:00,  5.51it/s]\n",
      "100%|██████████| 300/300 [00:54<00:00,  5.49it/s]\n",
      "100%|██████████| 300/300 [00:56<00:00,  5.29it/s]\n",
      "100%|██████████| 300/300 [00:53<00:00,  5.63it/s]\n",
      "  0%|          | 1/300 [00:00<00:47,  6.32it/s]C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:114: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss = np.sum((R - R_pred)**2) + np.sum((P - P_pred)**2) + np.sum((Q - Q_pred)**2)\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:106: RuntimeWarning: overflow encountered in matmul\n",
      "  R_pred = (U_mean + U) @ (V.T + V_mean)\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:106: RuntimeWarning: invalid value encountered in matmul\n",
      "  R_pred = (U_mean + U) @ (V.T + V_mean)\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:115: RuntimeWarning: overflow encountered in square\n",
      "  loss += lambdas[0] * np.sum(U**2) + lambdas[1] * np.sum(V**2) + lambdas[2] * np.sum(D**2) + lambdas[3] * np.sum(E**2)\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:142: RuntimeWarning: overflow encountered in multiply\n",
      "  dU = -2 * (R- R_pred) * (V.T + V_mean) - 2 * (P - P_pred) * E + 2 * lambdas[0] * U\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:102: RuntimeWarning: invalid value encountered in add\n",
      "  U_ += ue*U\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:139: RuntimeWarning: overflow encountered in matmul\n",
      "  R_pred = (U_mean + U) @ (V.T + V_mean)\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:139: RuntimeWarning: invalid value encountered in matmul\n",
      "  R_pred = (U_mean + U) @ (V.T + V_mean)\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:143: RuntimeWarning: overflow encountered in multiply\n",
      "  dV = -2 * (R - R_pred) * (U_mean + U) - 2 * (Q - Q_pred) * D + 2 * lambdas[1] * V\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:103: RuntimeWarning: invalid value encountered in add\n",
      "  V_ += ve*V\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:130: RuntimeWarning: invalid value encountered in add\n",
      "  V_ += ve*V\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:145: RuntimeWarning: invalid value encountered in multiply\n",
      "  dD = -2 * (Q - Q_pred) * V + 2 * lambdas[2] * D\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:129: RuntimeWarning: invalid value encountered in add\n",
      "  U_ += ue*U\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_4808\\448914457.py:144: RuntimeWarning: invalid value encountered in multiply\n",
      "  dE = -2 * (P - P_pred) * U + 2 * lambdas[3] * E\n",
      "100%|██████████| 300/300 [00:58<00:00,  5.11it/s]\n",
      "100%|██████████| 300/300 [00:54<00:00,  5.54it/s]\n",
      " 82%|████████▏ | 245/300 [00:45<00:10,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:55<00:00,  5.42it/s]\n",
      "c:\\Users\\thanh\\OneDrive - Queensland University of Technology\\dataPHD\\pytorchhere.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "100%|██████████| 300/300 [00:52<00:00,  5.68it/s]\n",
      "100%|██████████| 300/300 [00:54<00:00,  5.49it/s]\n",
      "100%|██████████| 300/300 [00:57<00:00,  5.25it/s]\n",
      "100%|██████████| 300/300 [05:27<00:00,  1.09s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.001, 'lambdas_': (0.01, 0.01, 0.01, 0.01), 'R_': array([[ 3.,  5., nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [ 4., nan,  4., ...,  4., nan, nan],\n",
      "       ...,\n",
      "       [ 1.,  1.,  1., ..., nan, nan, nan],\n",
      "       [ 4.,  4., nan, ..., nan, nan, nan],\n",
      "       [ 4., nan, nan, ..., nan, nan, nan]]), 'P_': 0, 'Q_': 0, 'U_': array([[0.00000000e+00, 0.00000000e+00, 8.28289214e-05, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 1.47212305e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.36722232e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 4.82477592e-01, 6.02104100e-01],\n",
      "       ...,\n",
      "       [4.10849997e-01, 2.13030244e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 2.12961343e-01, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 1.35958117e-02],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]), 'V_': array([[0.00000000e+00, 3.40021781e-04, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [3.61168348e-03, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       ...,\n",
      "       [6.61737116e-01, 6.92369706e-02, 5.73234207e-01, ...,\n",
      "        5.00038903e-01, 4.39096763e-01, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]), 'E_': 0, 'D_': 0, 'C_u_': array([[-0.75955453,  0.6917023 , -0.22860494],\n",
      "       [-0.75955453,  0.6917023 , -0.22860494],\n",
      "       [-0.75955453,  0.6917023 , -0.22860494],\n",
      "       ...,\n",
      "       [ 1.31656118, -1.44570866, -1.55220392],\n",
      "       [ 1.31656118, -1.44570866, -1.55220392],\n",
      "       [ 1.31656118, -1.44570866, -1.55220392]]), 'C_i_': array([[-0.75955453,  0.6917023 ,  0.22860494],\n",
      "       [-0.75955453,  0.6917023 ,  0.22860494],\n",
      "       [-0.75955453,  0.6917023 ,  0.22860494],\n",
      "       ...,\n",
      "       [ 1.31656118, -1.44570866,  1.55220392],\n",
      "       [ 1.31656118, -1.44570866,  1.55220392],\n",
      "       [ 1.31656118, -1.44570866,  1.55220392]]), 'L_U_': 0, 'L_V_': 0, 'b_u_': array([ 0.0690462 , -0.3622038 , -0.2684538 ,  0.8940462 ,  1.00237954,\n",
      "        0.42737954,  0.7940462 ,  0.2315462 ,  0.9190462 , -0.29148011,\n",
      "       -0.3309538 ,  0.11349065,  1.6690462 , -0.77539824,  0.2940462 ,\n",
      "       -0.10178713,  0.5440462 ,  0.05614298,  0.2940462 , -0.4309538 ,\n",
      "        0.75995529, -0.7059538 , -0.5809538 ,  1.2690462 ,  0.09761763,\n",
      "       -0.4809538 ,  0.31120307, -0.24399728,  0.1065462 , -1.07053713,\n",
      "        0.7940462 ,  0.00237954, -0.8809538 ,  0.70851989,  0.11135389,\n",
      "        0.36469838, -0.35178713, -0.9872038 , -1.0059538 , -0.10873158,\n",
      "        0.0440462 ,  0.00995529,  0.09497213, -0.1747038 , -0.40238237,\n",
      "       -1.03549925,  0.08351989, -1.1559538 ,  1.4502962 , -0.46556918,\n",
      "       -0.14913562, -0.2209538 ,  0.59960176,  0.4190462 ,  0.10952239,\n",
      "       -0.2059538 ,  0.25237954, -1.46556918, -1.2059538 , -0.26277198,\n",
      "        0.36547477,  0.62492856, -0.10979995,  0.23849065, -0.55317602,\n",
      "        0.0440462 , -0.74004471,  0.28015731,  0.03015731, -0.12640834,\n",
      "        0.59009883,  0.02618906,  0.53941657, -0.5809538 ,  0.33571287,\n",
      "       -0.04148011, -0.0497038 ,  0.80237954,  0.02618906,  0.1690462 ,\n",
      "       -0.27832222,  1.1690462 , -0.0809538 ,  1.6690462 ,  0.02321287,\n",
      "        0.22460176,  0.73571287, -0.21984269,  0.12737954,  0.64682398,\n",
      "       -0.03928713, -0.10018457,  0.29649718, -0.05317602, -1.8309538 ,\n",
      "        0.05793509, -0.68992816]), 'b_v_': array([ 0.64842765,  0.78669326,  0.71409125, -0.46428713,  0.81756105,\n",
      "       -0.97801262,  0.14465596,  0.10070088,  0.24596928,  0.69343645,\n",
      "        0.37374419, -0.09411169, -0.09691124,  0.40075352,  0.09587547,\n",
      "        0.03268257, -0.02213027,  0.20329278,  0.72737954,  0.84761763,\n",
      "       -0.16428713, -0.14576861,  1.00237954,  0.37234291,  0.1065462 ,\n",
      "       -0.58650935, -0.3622038 , -1.81482477,  0.05086438, -0.16428713,\n",
      "       -0.46428713, -0.12405725, -0.5559538 , -0.24860086,  0.10494364,\n",
      "       -0.8809538 ,  0.87957252, -0.28928713,  0.2290462 , -0.61036556,\n",
      "       -0.25403072,  0.48611937, -0.24987272, -0.57337804, -0.20274867,\n",
      "       -0.1533837 , -0.08650935,  0.19343645, -1.3309538 , -1.20238237,\n",
      "       -1.2215788 , -0.20933218, -0.2299437 , -0.88452523, -0.4679401 ,\n",
      "        0.85214479,  0.47606375,  0.36416815, -0.64762046, -0.7684538 ,\n",
      "       -0.4509538 , -0.42851477, -1.2059538 ,  0.31652822,  0.10807059,\n",
      "       -0.40787687,  0.77774185, -0.22381094, -0.7825667 , -1.9309538 ,\n",
      "       -0.8309538 , -0.45822652,  0.24047477, -1.27832222,  0.35823539,\n",
      "       -0.95000142, -0.06428713, -0.85334186,  0.24047477])}\n",
      "Best loss: 784.6351990044199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': [0.001, 0.01, 0.1],\n",
    "              'lambdas_': [(0.01, 0.01, 0.01, 0.01), \n",
    "                           (0.1, 0.1, 0.1, 0.1), \n",
    "                           (1, 1, 1, 1),(0.3, 0.3, 0.3, 0.3)],\n",
    "              'R_': [rating_matrix.values],\n",
    "              'P_': [0],\n",
    "              'Q_': [0],\n",
    "              'U_': [U_matrix],\n",
    "              'V_': [V_matrix],\n",
    "              'E_': [0],\n",
    "              'D_': [0],\n",
    "              'C_u_': [C_umatrix],\n",
    "              'C_i_': [C_imatrix],\n",
    "              'L_U_': [0],\n",
    "              'L_V_': [0],\n",
    "              'b_u_': [user_bias.values],\n",
    "              'b_v_': [item_bias.values]}\n",
    "best_params = grid_search(MultiMF, param_grid)\n",
    "alpha = best_params['alpha']\n",
    "lambdas = best_params['lambdas_']\n",
    "object = MultiMF(rating_matrix.values,0,0,U_matrix,V_matrix,0,0,C_umatrix,C_imatrix,0,0,lambdas,user_bias.values,item_bias.values,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:55<00:00,  5.43it/s]\n"
     ]
    }
   ],
   "source": [
    "U_result, V_result=object.factorize(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18a42c27e50>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(object.total_loss[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>itemid</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-0.000182</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.000182</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.000181</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.000181</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.000181</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.000163</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.000163</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.000163</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.000162</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.000162</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "itemid      0    1    2    3    4    5    6    7    8    9   ...  69  70   71  \\\n",
       "userid                                                       ...                \n",
       "-0.000182  3.0  5.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ... NaN NaN  NaN   \n",
       "-0.000182  NaN  NaN  NaN  NaN  NaN  NaN  NaN  4.0  NaN  NaN  ... NaN NaN  NaN   \n",
       "-0.000181  4.0  NaN  4.0  NaN  NaN  NaN  NaN  NaN  NaN  3.0  ... NaN NaN  NaN   \n",
       "-0.000181  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ... NaN NaN  NaN   \n",
       "-0.000181  NaN  NaN  4.0  NaN  NaN  NaN  NaN  5.0  NaN  NaN  ... NaN NaN  3.0   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ..  ..  ...   \n",
       "-0.000163  2.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  4.0  NaN  ... NaN NaN  NaN   \n",
       "-0.000163  5.0  NaN  NaN  4.0  4.0  NaN  3.0  3.0  NaN  4.0  ... NaN NaN  NaN   \n",
       "-0.000163  1.0  1.0  1.0  NaN  NaN  1.0  NaN  2.0  2.0  NaN  ... NaN NaN  NaN   \n",
       "-0.000162  4.0  4.0  NaN  NaN  NaN  NaN  3.0  4.0  NaN  NaN  ... NaN NaN  NaN   \n",
       "-0.000162  4.0  NaN  NaN  NaN  3.0  NaN  NaN  1.0  NaN  NaN  ... NaN NaN  NaN   \n",
       "\n",
       "itemid      72   73   74   75   76   77   78  \n",
       "userid                                        \n",
       "-0.000182  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "-0.000182  NaN  NaN  NaN  4.0  NaN  NaN  NaN  \n",
       "-0.000181  NaN  1.0  4.0  NaN  4.0  NaN  NaN  \n",
       "-0.000181  NaN  NaN  5.0  NaN  NaN  NaN  NaN  \n",
       "-0.000181  4.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "...        ...  ...  ...  ...  ...  ...  ...  \n",
       "-0.000163  4.0  NaN  4.0  NaN  NaN  NaN  NaN  \n",
       "-0.000163  3.0  1.0  3.0  NaN  NaN  3.0  3.0  \n",
       "-0.000163  NaN  NaN  1.0  NaN  NaN  NaN  NaN  \n",
       "-0.000162  NaN  NaN  2.0  NaN  NaN  NaN  NaN  \n",
       "-0.000162  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[97 rows x 79 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler=MinMaxScaler(feature_range=(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "R_pred=np.dot(U_result,V_result)\n",
    "R_pred=mmscaler.fit_transform(R_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_10_precision(predicted_ratings, real_ratings):\n",
    "    precision_sum = 0\n",
    "    users_count = real_ratings.shape[0]\n",
    "\n",
    "    for user_idx in range(users_count):\n",
    "        user_real_ratings = real_ratings.values[user_idx]\n",
    "        user_predicted_ratings = predicted_ratings[user_idx]\n",
    "\n",
    "        # Get the indices of the top-10 predicted ratings\n",
    "        top_10_predicted_indices = np.argsort(user_predicted_ratings)[-10:]\n",
    "\n",
    "        # Get the indices of the user's real ratings\n",
    "        real_rated_indices = np.where(~np.isnan(user_real_ratings))[0]\n",
    "\n",
    "        # Calculate the number of relevant items in the top-10 predicted items\n",
    "        relevant_items_count = np.sum(np.isin(top_10_predicted_indices, real_rated_indices))\n",
    "\n",
    "        # Calculate the precision for the current user\n",
    "        user_precision = relevant_items_count / 10\n",
    "\n",
    "        # Update the precision sum\n",
    "        precision_sum += user_precision\n",
    "\n",
    "    # Calculate the average precision across all users\n",
    "    average_precision = precision_sum / users_count\n",
    "\n",
    "    return average_precision\n",
    "\n",
    "def top_1_precision(predicted_ratings, real_ratings):\n",
    "    precision_sum = 0\n",
    "    users_count = real_ratings.shape[0]\n",
    "\n",
    "    for user_idx in range(users_count):\n",
    "        user_real_ratings = real_ratings.values[user_idx]\n",
    "        user_predicted_ratings = predicted_ratings[user_idx]\n",
    "\n",
    "        # Get the indices of the top-10 predicted ratings\n",
    "        top_10_predicted_indices = np.argsort(user_predicted_ratings)[-1:]\n",
    "\n",
    "        # Get the indices of the user's real ratings\n",
    "        real_rated_indices = np.where(~np.isnan(user_real_ratings))[0]\n",
    "\n",
    "        # Calculate the number of relevant items in the top-10 predicted items\n",
    "        relevant_items_count = np.sum(np.isin(top_10_predicted_indices, real_rated_indices))\n",
    "\n",
    "        # Calculate the precision for the current user\n",
    "        user_precision = relevant_items_count \n",
    "\n",
    "        # Update the precision sum\n",
    "        precision_sum += user_precision\n",
    "\n",
    "    # Calculate the average precision across all users\n",
    "    average_precision = precision_sum / users_count\n",
    "\n",
    "    return average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7515463917525772"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_precision(R_pred,rating_matrix)\n",
    "top_1_precision(R_pred,rating_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8969072164948454"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_1_precision(R_pred,rating_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = NMF(n_components=52, init='random', random_state=0)\n",
    "z = model.fit_transform(X)\n",
    "c = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_pred_benchmark1 = np.dot(z,c)\n",
    "R_pred_benchmark1=mmscaler.fit_transform(R_pred_benchmark1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10206185567010304\n",
      "0.10309278350515463\n"
     ]
    }
   ],
   "source": [
    "print(top_10_precision(R_pred_benchmark1,rating_matrix))\n",
    "print(top_1_precision(R_pred_benchmark1,rating_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predicted_ratings, real_ratings):\n",
    "    # Create a mask of the same shape as real_ratings with True where there's a rating and False where there's NaN\n",
    "    mask = ~np.isnan(real_ratings)\n",
    "\n",
    "    # Calculate the squared error between the predicted and real ratings only for the rated items\n",
    "    squared_error = (predicted_ratings[mask] - real_ratings[mask])**2\n",
    "\n",
    "    # Calculate the mean squared error\n",
    "    mean_squared_error = np.mean(squared_error)\n",
    "\n",
    "    # Calculate the root mean squared error\n",
    "    root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "\n",
    "    return root_mean_squared_error\n",
    "\n",
    "def mae(predicted_ratings, real_ratings):\n",
    "    # Create a mask of the same shape as real_ratings with True where there's a rating and False where there's NaN\n",
    "    mask = ~np.isnan(real_ratings)\n",
    "\n",
    "    # Calculate the absolute error between the predicted and real ratings only for the rated items\n",
    "    absolute_error = np.abs(predicted_ratings[mask] - real_ratings[mask])\n",
    "\n",
    "    # Calculate the mean absolute error\n",
    "    mean_absolute_error = np.mean(absolute_error)\n",
    "\n",
    "    return mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10:  0.7515463917525772\n",
      "Top 1 Precision:  0.8969072164948454\n",
      "RMSE:  0.9088766836358088\n",
      "MAE:  0.7595287595287595\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10: \",top_10_precision(R_pred,rating_matrix))\n",
    "print(\"Top 1 Precision: \",top_1_precision(R_pred,rating_matrix))\n",
    "print(\"RMSE: \",rmse(R_pred,rating_matrix.values))\n",
    "print(\"MAE: \",mae(R_pred,rating_matrix.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['Top10']= top_10_precision(R_pred,rating_matrix)\n",
    "result['Top1']= top_1_precision(R_pred,rating_matrix)\n",
    "result['RMSE']= top_10_precision(R_pred,rating_matrix)\n",
    "result['alpha']= best_params['alpha']\n",
    "result['lambdas_']= best_params['lambdas_']\n",
    "result.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.01, 0.01, 0.01)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params['alpha']\n",
    "best_params['lambdas_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
